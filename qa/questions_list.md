# SE-ResNet CIFAR图像分类汇报问题列表

## 理论理解类问题
1. 请详细解释SE模块的工作原理，特别是它如何捕捉通道间的依赖关系？
2. 为什么SE-ResNet比普通ResNet更适合图像分类任务？
3. 请解释ResNet中的残差连接如何解决深层网络的梯度消失问题？
4. SE模块中的缩减率(reduction ratio)参数有什么作用？如何选择合适的值？
5. 汇报中提到SE模块仅增加约5%的参数量，为什么它能在较小的计算开销下取得显著的性能提升？

## 实验设计类问题
1. 为什么在消融实验中选择了这些特定组件(SE模块、Dropout、数据增强)进行分析？
2. 数据增强对模型性能影响最大，你认为原因是什么？
3. 你如何确定模型中的超参数，如SE缩减率和Dropout率的最佳值？
4. 为什么在CIFAR-100上增加了Dropout率到0.6而不是沿用CIFAR-10上的0.5？
5. 在实验中使用了哪些评估指标？为什么选择这些指标？

## 结果分析类问题
1. CIFAR-10和CIFAR-100的结果差异较大，你认为主要原因是什么？
2. 在CIFAR-10的类别中,"cat"类的准确率最低，你认为可能的原因是什么？
3. 从消融实验结果看，为什么不使用Dropout时测试损失更低，但准确率却下降了？
4. 在SE模块的消融实验中，性能提升了0.94个百分点，你认为这个提升幅度是否显著？为什么？
5. 不同类别的识别准确率差异很大，如何改进模型使其在各类别上表现更加均衡？

## 技术实现类问题
1. 你在实现SE模块时遇到了哪些技术难点，如何解决的？
2. 代码中如何处理CIFAR数据集的小图像尺寸问题？
3. 模型训练过程中使用了哪些优化策略来提高收敛效率？
4. 为什么选择AdamW优化器而不是传统的SGD或Adam？
5. 代码中的学习率调整策略是如何实现的？为什么选择余弦退火策略？

## 未来工作类问题
1. 你提到了其他注意力机制如CBAM、ECA等，它们与SE模块相比有什么优缺点？
2. 如何进一步提高模型在"cat"等识别困难类别上的性能？
3. 你认为该模型架构可以应用到哪些实际场景中？
4. 如果要将模型部署到资源受限的设备上，有哪些可能的优化方向？
5. 除了注意力机制，还有哪些可能的方向可以提升ResNet在CIFAR数据集上的性能？ 