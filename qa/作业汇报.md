# 基于SE-ResNet的CIFAR图像分类作业汇报

## 一、模型介绍

### 1.1 模型架构

本项目使用改进版ResNet（SE-ResNet）对CIFAR10和CIFAR100数据集进行图像分类。SE-ResNet是在传统ResNet架构基础上添加了Squeeze-and-Excitation（SE）注意力机制的深度卷积神经网络。具体实现了两种变体：

- **SE-ResNet18**：包含18层卷积层的轻量级模型
- **SE-ResNet34**：包含34层卷积层的更深层次模型

### 1.2 SE注意力机制

SE模块是本项目的核心创新点，它通过显式建模通道间的相互依赖关系，自适应地调整特征通道的重要性权重，从而提升模型的表示能力。SE模块的工作原理分为三个步骤：

1. **Squeeze操作**：通过全局平均池化将每个特征通道的空间信息压缩为单个数值，生成通道描述符
2. **Excitation操作**：使用两个全连接层和非线性激活函数，学习通道间的非线性关系，生成每个通道的重要性权重
3. **重新校准**：将学习到的权重应用于原始特征图，增强重要通道的特征，抑制不重要通道的特征

![pEsslIe.png](https://s21.ax1x.com/2025/03/31/pEsslIe.png)

### 1.3 为什么选择这种架构？

选择SE-ResNet架构的主要原因有：

1. **ResNet的优势**：
   - 残差连接有效解决了深层网络的梯度消失问题
   - 批归一化（Batch Normalization）加速了训练过程
   - 在各种计算机视觉任务中已被证明是有效的基础架构

2. **SE模块的优势**：
   - 引入注意力机制，使模型能够更好地捕捉到不同特征通道的重要性
   - 计算开销相对较小（仅增加~5%的参数量）
   - 可以无缝集成到现有的ResNet架构中
   - 通过SE模块的缩减率参数，可以灵活调整性能与计算成本的平衡

3. **适应CIFAR数据集的修改**：
   - 针对CIFAR10/100的小尺寸图像(32x32)，调整了网络初始层的卷积核大小和步长
   - 添加Dropout层缓解过拟合问题
   - 使用AdamW优化器和Cosine学习率调度策略提高收敛效率

## 二、实验结果

### 2.1 CIFAR-10数据集结果

在CIFAR-10数据集上，使用SE-ResNet18模型实现的最终测试精度为**92.36%**。

详细测试结果：
- 测试损失：0.4615
- 测试样本数量：10000
- 测试时间：27.21秒

各类别准确率排名：
1. automobile: 97.10%
2. frog: 95.80%
3. ship: 95.50%
4. truck: 95.30%
5. airplane: 93.70%
6. horse: 93.40%
7. deer: 91.60%
8. bird: 89.20%
9. dog: 88.80%
10. cat: 83.20%

整体性能指标：
- 总体精确率 (macro avg precision): 0.9235
- 总体召回率 (macro avg recall): 0.9236
- 总体F1分数 (macro avg f1-score): 0.9235

### 2.2 CIFAR-100数据集结果

在CIFAR-100数据集上，使用相同的SE-ResNet18架构，模型达到了约**70%**的测试准确率。相比CIFAR-10，CIFAR-100因为类别数量更多(100个类别)，分类难度更大，所以准确率相对较低，这符合预期。

CIFAR-100上的主要优化措施：
- 增加Dropout率到0.6以减轻更严重的过拟合问题
- 增加权重衰减系数到5e-4
- 训练轮数增加到150轮

## 三、消融实验结果

为了验证模型各组件的有效性，我们在CIFAR-10数据集上进行了一系列消融实验，通过移除或修改模型的某些关键组件，来评估它们对最终性能的贡献。

### 3.1 SE模块消融实验

|                | 使用SE模块 | 不使用SE模块 | 差异    |
|----------------|-----------|------------|---------|
| 测试准确率     | 92.36%    | 91.42%     | -0.94%  |
| 测试损失       | 0.4615    | 0.3415     | -0.12   |
| 各类别平均差异 | -         | -          | -0.94%  |

**结论**：SE模块提升了模型整体性能约0.94个百分点，证明了注意力机制确实能够增强模型对特征通道重要性的理解。

### 3.2 Dropout消融实验

|                | 使用Dropout(0.5) | 不使用Dropout | 差异    |
|----------------|-----------------|--------------|---------|
| 测试准确率     | 92.36%          | 91.97%       | -0.39%  |
| 测试损失       | 0.4615          | 0.3353       | -0.1262 |
| 各类别平均差异 | -               | -            | -0.39%  |

**结论**：Dropout正则化对模型性能有轻微提升，虽然不使用Dropout时测试损失更低，但准确率也略有下降，表明Dropout确实起到了减轻过拟合的作用。

### 3.3 数据增强消融实验

|                | 完整数据增强 | 基础数据增强 | 差异    |
|----------------|------------|------------|---------|
| 测试准确率     | 92.36%     | 85.69%     | -6.67%  |
| 测试损失       | 0.4615     | 0.8688     | +0.4073 |
| 各类别平均差异 | -          | -          | -6.67%  |

**结论**：数据增强对模型性能的提升最为显著，去除高级数据增强（随机裁剪、水平翻转和颜色抖动）后，性能下降了6.67个百分点。这说明在训练样本有限的情况下，数据增强是提高模型泛化能力的关键手段。

### 3.4 消融实验总结

通过消融实验可以得出以下结论：

1. **数据增强**对模型性能影响最大，是提高泛化能力的关键
2. **SE注意力机制**能有效提升模型性能约1个百分点，证明了其有效性
3. **Dropout正则化**对防止过拟合有帮助，但影响相对较小
4. 性能提升从大到小排序：数据增强 > SE模块 > Dropout

这些实验结果为改进深度学习模型提供了明确的方向，尤其是在处理图像分类任务时，应优先考虑良好的数据增强策略，其次是添加适当的注意力机制。

## 四、代码运行演示

为了演示代码的正常运行，我录制了一段视频，展示了模型训练、测试和消融实验的完整流程。

### 4.1 代码运行步骤

1. **环境准备**
   - 激活conda环境：`conda activate dlenv`
   - 确保所有依赖已安装：Python 3.6+, PyTorch 1.7+, torchvision, matplotlib, numpy, scikit-learn, seaborn

2. **基础模型训练**
   ```bash
   python train.py --dataset cifar10 --model se_resnet18 --batch_size 128 --epochs 100 --save_dir checkpoints/cifar10_resnet18 --final_test
   ```

3. **消融实验运行**
   ```bash
   # 无SE模块实验
   python train.py --dataset cifar10 --model se_resnet18 --use_se False --batch_size 128 --epochs 100 --save_dir checkpoints/cifar10_without_se --final_test
   
   # 无Dropout实验
   python train.py --dataset cifar10 --model se_resnet18 --dropout_rate 0.0 --batch_size 128 --epochs 100 --save_dir checkpoints/cifar10_no_dropout --final_test
   
   # 无数据增强实验
   python train.py --dataset cifar10 --model se_resnet18 --no_augmentation --batch_size 128 --epochs 100 --save_dir checkpoints/cifar10_basic_aug --final_test
   ```

4. **模型测试与分析**
   ```bash
   python test_model.py --dataset cifar10 --model se_resnet18 --checkpoint checkpoints/cifar10_resnet18/cifar10_se_resnet18_best.pth.tar
   ```


未来工作可以从以下几个方面展开：
1. 尝试其他注意力机制如CBAM、ECA等
2. 探索更高效的网络架构如MobileNet, EfficientNet等
3. 应用更先进的数据增强策略如AutoAugment, RandAugment等
4. 尝试蒸馏技术进一步提升模型性能

## 参考文献

1. He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. CVPR.
2. Hu, J., Shen, L., & Sun, G. (2018). Squeeze-and-excitation networks. CVPR.
3. Loshchilov, I., & Hutter, F. (2019). Decoupled weight decay regularization. ICLR.
4. Krizhevsky, A., & Hinton, G. (2009). Learning multiple layers of features from tiny images. Technical Report. 